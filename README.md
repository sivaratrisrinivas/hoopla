# Hoopla

A movie search engine that combines BM25 ranking and semantic search to find relevant movies from large datasets.

---

## What is Hoopla?

Hoopla is a command-line tool that searches through thousands of movie descriptions using two complementary approaches:

- **BM25 Search**: Smart keyword matching that considers word frequency, rarity, and document length
- **Semantic Search**: AI-powered understanding that finds conceptually similar movies even without exact keyword matches

Together, these methods can be combined for even better results.

---

## Why Two Approaches?

**Traditional keyword search** only finds exact word matches. **BM25** is smarter—it considers how often words appear, how rare they are, and adjusts for document length. **Semantic search** goes further by understanding meaning and context, finding movies that are similar in concept even if they don't share keywords.

---

## Installation

```bash
# Clone the repository
git clone <repository-url>
cd hoopla

# Install dependencies (uv recommended)
uv sync

# Or using pip
pip install -e .

# Optional: For RAG and query enhancement, add to .env:
# GEMINI_API_KEY=your_api_key_here
```

---

## Data Setup

Place your movie dataset at `data/movies.json`:

```json
{
  "movies": [
    {
      "id": 1,
      "title": "Movie Title",
      "description": "Movie description..."
    }
  ]
}
```

Also ensure `data/stopwords.txt` exists (one stopword per line).

---

## How It Works

### Keyword Search (BM25)
1. **Index Building**: Creates an inverted index (like a book's index, but for every word)
2. **Text Processing**: Cleans and stems words (e.g., "running" → "run")
3. **Smart Scoring**: Uses BM25 algorithm to rank results by relevance

### Semantic Search
1. **Model Loading**: Loads pre-trained sentence transformer model (all-MiniLM-L6-v2)
2. **Text Embedding**: Converts queries and descriptions into high-dimensional vectors
3. **Similarity Matching**: Finds movies with similar meaning using cosine similarity
4. **Chunking**: Splits long text into manageable chunks for better processing

### Hybrid Search
1. **Dual Query**: Runs both BM25 and semantic search simultaneously
2. **Result Merging**: Combines results from both approaches
3. **Ranking**: Sorts merged results by relevance score

---

## Quick Start

### 1. Setup

```bash
# Build search index (required first step)
python cli/keyword_search_cli.py build

# Precompute semantic embeddings (recommended)
python cli/semantic_search_cli.py embed_chunks
```

### 2. Basic Searches

```bash
# Keyword search
python cli/keyword_search_cli.py bm25search "romantic comedy" --limit 10

# Semantic search
python cli/semantic_search_cli.py search "space adventure" --limit 5

# Hybrid search (best results)
python cli/hybrid_search_cli.py rrf-search "superhero action movie" --limit 10
```

### 3. Advanced Features

```bash
# Query enhancement (spell correction)
python cli/hybrid_search_cli.py rrf-search "briish bear" --enhance spell

# Query rewriting (makes vague queries searchable)
python cli/hybrid_search_cli.py rrf-search "bear movie that gives me the lulz" --enhance rewrite

# Reranking (improves result quality)
python cli/hybrid_search_cli.py rrf-search "action movie" --rerank-method cross_encoder --limit 25

# Multimodal query rewriting (image + text)
python cli/describe_image_cli.py --image data/paddington.jpeg --query "find movies like this"

# Verify image embedding generation
python cli/multimodal_search_cli.py verify_image_embedding data/paddington.jpeg

# Search movies using image
python cli/multimodal_search_cli.py image_search data/paddington.jpeg
```

### 4. RAG (AI-Powered Answers)

```bash
# Generate comprehensive answer
python cli/augmented_generation_cli.py rag "movies about time travel"

# Summarize results
python cli/augmented_generation_cli.py summarize "action movies" --limit 10

# Answer with citations
python cli/augmented_generation_cli.py citations "time travel movies" --limit 10

# Casual Q&A
python cli/augmented_generation_cli.py question "What are some good horror movies?" --limit 10
```

---

## Commands Reference

### Keyword Search (`keyword_search_cli.py`)

| Command | Description |
|---------|-------------|
| `build` | Create search index from movie data |
| `search <query>` | Basic keyword search (exact matching) |
| `bm25search <query>` | BM25-ranked search |
| `tf <doc_id> <term>` | Get term frequency |
| `idf <term>` | Get inverse document frequency |
| `tfidf <doc_id> <term>` | Get TF-IDF score |
| `bm25idf <term>` | Get BM25-IDF score |
| `bm25tf <doc_id> <term>` | Get BM25 term frequency |

### Semantic Search (`semantic_search_cli.py`)

| Command | Description |
|---------|-------------|
| `verify` | Verify embedding model is loaded |
| `verify_embeddings` | Verify movie embeddings and show stats |
| `search <query>` | Semantic similarity search |
| `embed_chunks` | Precompute sentence-chunk embeddings |
| `search_chunked <query> [--limit <int>]` | Search using chunked embeddings |
| `chunk <text> [--chunk-size <int>] [--overlap <int>]` | Split into word chunks |
| `semantic_chunk <text> [--max-chunk-size <int>] [--overlap <int>]` | Split into sentence chunks |

### Hybrid Search (`hybrid_search_cli.py`)

| Command | Description |
|---------|-------------|
| `hybrid_search <query> [--limit <int>]` | Combine BM25 + semantic results |
| `weighted-search <query> [--alpha <float>] [--limit <int>]` | Weighted combination (alpha: 0.0=semantic, 1.0=BM25, default 0.5) |
| `rrf-search <query> [--k <int>] [--limit <int>] [--enhance <method>] [--rerank-method <method>] [--evaluate]` | Reciprocal Rank Fusion |
| `normalize <scores...>` | Min-max normalization to [0, 1] |

**RRF Search Options:**
- `--enhance`: `spell` (correction), `rewrite` (query rewriting), `expand` (synonyms)
- `--rerank-method`: `individual` (LLM per result), `batch` (single LLM call), `cross_encoder` (local model)
- `--evaluate`: Rate results 0-3 for relevance

### RAG (`augmented_generation_cli.py`)

| Command | Description |
|---------|-------------|
| `rag <query>` | Search + generate comprehensive answer |
| `summarize <query> [--limit <int>]` | Generate concise 3-4 sentence summary |
| `citations <query> [--limit <int>]` | Generate answer with [1], [2] citations |
| `question <question> [--limit <int>]` | Casual, conversational Q&A |

**Note**: RAG commands require `GEMINI_API_KEY` in `.env` or environment variables.

### Evaluation (`evaluation_cli.py`)

| Command | Description |
|---------|-------------|
| `evaluation_cli.py [--limit <int>]` | Evaluate search performance using golden dataset (precision@k, recall@k, F1) |

### Multimodal Query Rewriting (`describe_image_cli.py`)

| Command | Description |
|---------|-------------|
| `--image <path>` | Path to image file (required) |
| `--query <text>` | Text query to rewrite based on image (required) |

**Note**: Requires `GEMINI_API_KEY` in `.env` or environment variables.

### Multimodal Search (`multimodal_search_cli.py`)

| Command | Description |
|---------|-------------|
| `verify_image_embedding <image>` | Verify image embedding generation (512-dimensional CLIP embeddings) |
| `image_search <image>` | Search for movies using image similarity (returns top 5 matches) |

---

## Technical Details

### Keyword Search
- **Library**: NLTK for text processing and stemming
- **Algorithm**: BM25 with parameters k1=1.5, b=0.75
- **Caching**: Processed data cached for performance
- **Features**: Custom search limits, detailed TF-IDF/BM25 scoring

### Semantic Search
- **Model**: `all-MiniLM-L6-v2` (sentence-transformers)
- **Embeddings**: 384-dimensional vectors
- **Cache**: `cache/movie_embeddings.npy` (auto-rebuilt if dataset changes)
- **Context**: Combines titles + descriptions for richer understanding
- **Defaults**: CPU device, search limit 5
- **Chunking**: Default size 200 words, overlap 1; sentence chunks default to 4 sentences

**Precompute chunked embeddings:**
```bash
python cli/semantic_search_cli.py embed_chunks
# Expected: "Generated 72909 chunked embeddings"
```

**Rebuild cache:**
```bash
rm cache/chunk_embeddings.npy cache/chunk_metadata.json
python cli/semantic_search_cli.py embed_chunks
```

### Hybrid Search

**Weighted Hybrid Search**
- Formula: `hybrid_score = alpha * normalized_bm25 + (1 - alpha) * normalized_semantic`
- Searches top 2500 from each method, normalizes scores, combines, returns top `--limit`

**Reciprocal Rank Fusion (RRF)**
- Formula: `rrf_score = 1 / (k + rank)` (default k=60)
- Uses ranks (position) rather than scores, robust to different score distributions
- Documents in both result sets have RRF scores summed

**Reranking Methods:**
- `individual`: LLM scores each result (0-10 scale), slower, more API calls
- `batch`: LLM reranks all results in single call, faster, fewer API calls
- `cross_encoder`: Local neural network model, fastest, no API key required

**Query Enhancement:**
- `spell`: Corrects spelling errors
- `rewrite`: Rewrites vague queries to be more searchable
- `expand`: Expands queries with synonyms and related terms

**Result Evaluation:**
- Rates results 0-3 (3=Highly relevant, 2=Relevant, 1=Marginally relevant, 0=Not relevant)

### RAG (Retrieval Augmented Generation)
- **Search**: RRF (k=60), retrieves `limit * 5` results (default: 25)
- **Model**: Gemini 2.0 Flash
- **Context**: Movie titles + descriptions
- **Commands**:
  - `rag`: Comprehensive answers
  - `summarize`: 3-4 sentence summaries
  - `citations`: Answers with [1], [2] source citations
  - `question`: Casual, conversational Q&A
- **Output**: Search result titles → AI-generated answer/summary

### Evaluation
- **Dataset**: `data/golden_dataset.json` (queries + expected relevant titles)
- **Metrics**: Precision@k, Recall@k, F1 score
- **Method**: RRF search (k=60) for retrieval

### Multimodal Query Rewriting
- **Model**: Gemini 2.0 Flash
- **Input**: Image file + text query
- **Process**: Analyzes image content, synthesizes with text query, rewrites for movie search
- **Output**: Rewritten query optimized for movie database search + token usage
- **MIME Types**: Auto-detects image format (JPEG, PNG, etc.), defaults to JPEG

### Multimodal Search
- **Model**: CLIP ViT-B-32 (sentence-transformers)
- **Embeddings**: 512-dimensional vectors
- **Device**: CPU by default (CUDA disabled to prevent GPU mismatches)
- **Purpose**: Generate image embeddings for visual similarity search
- **Search**: Compares image embeddings with movie title+description text embeddings using cosine similarity
- **Format**: Movies formatted as "title: description" for CLIP text encoding

### Performance
- **Device**: CPU by default (CUDA disabled to prevent GPU mismatches)
- **Caching**: Indexes and embeddings cached for fast repeated searches
- **Defaults**: Search limit 5, RRF k=60, search multiplier 5

---

## Output Format

**Chunked semantic search:**
```
1. The Incredibles (score: 0.8123)
   A family of undercover superheroes, while trying to live the quiet suburban life...
```

**RRF search:**
```
Movie Title (RRF score: 0.0234, BM25 rank: 3, Semantic rank: 5)
Description preview...
```

**RAG:**
```
Search Results:
  - Movie Title 1
  - Movie Title 2

RAG Response:
[AI-generated answer]
```

**Multimodal query rewriting:**
```
Rewritten query: Paddington Bear family-friendly animated adventure movies
Total tokens:    1234
```

**Multimodal search:**
```
Image search results for: data/paddington.jpeg
============================================================
1. Paddington (similarity: 0.309)
   A young Peruvian bear travels to London in search of a home...
2. Paddington 2 (similarity: 0.285)
   Paddington, now happily settled with the Brown family...
```

---

## Notes

- All search methods require the keyword index (`build` command)
- Hybrid search and RAG require chunked embeddings (`embed_chunks` command)
- RAG and multimodal query rewriting require `GEMINI_API_KEY` for AI features
- Cache files are automatically rebuilt if dataset size changes
- The system runs on CPU by default to avoid GPU compatibility issues
